{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.cuda.amp import autocast, GradScaler\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define AlexNet Model for CIFAR-10","metadata":{}},{"cell_type":"code","source":"class AlexNetCIFAR10(nn.Module):\n    def __init__(self, num_classes=10):\n        super(AlexNetCIFAR10, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.ReLU(inplace=False),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=False),\n            nn.MaxPool2d(kernel_size=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=False),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=False),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=False),\n            nn.MaxPool2d(kernel_size=2),\n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(256 * 4 * 4, 1024),\n            nn.ReLU(inplace=False),\n            nn.Dropout(0.5),\n            nn.Linear(1024, 512),\n            nn.ReLU(inplace=False),\n            nn.Linear(512, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        return self.classifier(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Helper Functions for Model Handling","metadata":{}},{"cell_type":"code","source":"def get_model(device=\"cuda\"):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = AlexNetCIFAR10().to(device)\n    return model\n\ndef load_model(device=\"cuda\"):\n    model = get_model(device)\n    state_dict = torch.load(\"/kaggle/input/alexnet_cifar10_best/pytorch/w/1/best_alexnet_cifar10.pth\", map_location=\"cpu\")\n    model.load_state_dict(state_dict)\n    model.to(device)\n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" Load model and weights","metadata":{}},{"cell_type":"code","source":"def mixup_data(x, y, alpha=1.0):\n    lam = np.random.beta(alpha, alpha)\n    index = torch.randperm(x.size(0)).to(x.device)\n    mixed_x = lam * x + (1 - lam) * x[index]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AlexNetCIFAR10().to(device)\nmodel.load_state_dict(torch.load(\"/kaggle/input/alexnet_cifar10_best/pytorch/w/1/best_alexnet_cifar10.pth\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Loss and Optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"CIFAR-10 loaders","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\ndef get_data_loaders(batch_size=128):\n    transform = transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomCrop(32, padding=4),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n    ])\n\n    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n\n    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n    return trainloader, testloader\n\ntrain_loader, test_loader = get_data_loaders()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Train for more epochs","metadata":{}},{"cell_type":"code","source":"num_epochs = 1\nfor epoch in range(num_epochs):\n    model.train()\n    total, correct, running_loss = 0, 0, 0.0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Acc: {100*correct/total:.2f}%\")\n\nepoch_set = 700","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Knowledge distillation ","metadata":{}},{"cell_type":"code","source":"def knowledge_distillation(teacher, student, dataloader, device=\"cuda\"):\n    loss_fn = nn.KLDivLoss(reduction=\"batchmean\")\n    optimizer = optim.Adam(student.parameters(), lr=1e-4)\n    student.train()\n    for images, _ in dataloader:\n        images = images.to(device)\n        with torch.no_grad():\n            teacher_outputs = teacher(images)\n        student_outputs = student(images)\n        loss = loss_fn(student_outputs.log_softmax(dim=1), teacher_outputs.softmax(dim=1))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\ndef mixup_data(x, y, alpha=1.0):\n    lam = np.random.beta(alpha, alpha)\n    index = torch.randperm(x.size(0)).to(x.device)\n    mixed_x = lam * x + (1 - lam) * x[index]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Helper Functions","metadata":{}},{"cell_type":"code","source":"def fine_tune_model(model, trainloader, testloader, epochs = epoch_set, lr=0.01, weight_decay= 5e-4, accumulation_step=4, device=\"cuda\"):\n    model.to(device)\n    model.train()\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\noptimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=2)\n    scaler = GradScaler()\n\nbest_acc = 0\n    early_stop_counter = 0\n    patience = 12  # Stop early if no improvement in 12 epochs\n\n    for epoch in range(epochs):\n        running_loss = 0.0\n        correct, total = 0, 0\n        optimizer.zero_grad()\n\n\nfor i, (images, labels) in enumerate(trainloader):\n            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n\n            with autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels) / accumulation_steps\n\n            scaler.scale(loss).backward()\n\n            if (i + 1) % accumulation_steps == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n\nrunning_loss += loss.item() * accumulation_steps\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n\n# Free memory every 5 steps\n            if i % 5 == 0:\n                del images, labels, outputs, loss, predicted\n                torch.cuda.empty_cache()\n                torch.cuda.synchronize()\n\n        test_acc = test_model(model, testloader)\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n\n        scheduler.step()\n\n        if test_acc > best_acc:\n            best_acc = test_acc\n            early_stop_counter = 0\n\nelse:\n            early_stop_counter += 0\n            if early_stop_counter >= patience:\n                print(\"Early stopping triggered.\")\n                break\n\n    print(\"Fine-tuning complete. Best Test Accuracy:\", best_acc)\n    return best_acc\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Fine Tune","metadata":{}},{"cell_type":"code","source":"def fine_tune_base_model(model, trainloader, testloader, epochs=epoch_set, lr=0.01, weight_decay=5e-4, accumulation_steps=4, device=\"cuda\"):\n    model.to(device)\n    model.train()\n\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=2)\n    scaler = GradScaler()\n\nbest_acc = 0\n    early_stop_counter = 0\n    patience = 5 # Stop early if no improvement in 2 epochs\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n   loop = tqdm(trainloader, desc=f\"Epoch [{epoch+1}/{epochs}]\")\n\n        for images, labels in loop:\n            images, labels = images.to(device), labels.to(device)\n\n      # ✅ Apply MixUp\n            images, y_a, y_b, lam = mixup_data(images, labels, alpha=1.0)\n            outputs = model(images)\n            loss = mixup_criterion(criterion, outputs, y_a, y_b, lam)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            loop.set_postfix(loss=loss.item())\n\n        scheduler.step()        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Evaluate","metadata":{}},{"cell_type":"code","source":"model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in testloader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = outputs.max(1)\n                total += labels.size(0)\n                correct += predicted.eq(labels).sum().item()\n\n        acc = 100. * correct / total\n        print(f\"Epoch {epoch+1} - Test Accuracy: {acc:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Save best model","metadata":{}},{"cell_type":"code","source":"if acc > best_acc:\n            best_acc = acc\n            best_model = model\n            print(f\"Accuracy: {acc:.2f}%\")\n    return best_model, best_acc\n\nfrom torch.cuda.amp import autocast, GradScaler\nimport torch.nn.functional as F\n\ndef fine_tune_with_kd(student_model, teacher_model, trainloader, testloader,\n                      epochs=700, lr=1e-4, weight_decay=1e-4, accumulation_steps=4,\n                      alpha=0.5, temperature=4.0, device=\"cuda\", patience=10):\n    \"\"\"\n    Fine-tune a pruned student model using improved KD from a teacher model.\n    \"\"\"\n    import torch.nn.functional as F\n    from torch.cuda.amp import autocast, GradScaler\n    import torch\n    from torch import nn, optim\n\n    student_model.to(device)\n    teacher_model.to(device)\n    teacher_model.eval()\n\n    optimizer = optim.AdamW(student_model.parameters(), lr=lr, weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n    ce_criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label smoothing\n    kd_criterion = nn.KLDivLoss(reduction=\"batchmean\")\n    scaler = GradScaler()\n\n    best_acc = 0.0\n    early_stop_counter = 0\n\n    for epoch in range(epochs):\n        student_model.train()\n        running_loss = 0.0\n        correct, total = 0, 0\n        optimizer.zero_grad()\n\n        for i, (images, labels) in enumerate(trainloader):\n            images, labels = images.to(device), labels.to(device)\n\n            with autocast():\n                student_outputs = student_model(images)\n                with torch.no_grad():\n                    teacher_outputs = teacher_model(images)\n\n                # Soft targets with sharpening\n                teacher_probs = F.softmax(teacher_outputs / temperature, dim=1)\n                teacher_probs = teacher_probs.clamp(min=1e-7, max=1.0)  # prevent log(0)\n                student_log_probs = F.log_softmax(student_outputs / temperature, dim=1)\n\n                # Compute losses\n                kd_loss = kd_criterion(student_log_probs, teacher_probs)\n                ce_loss = ce_criterion(student_outputs, labels)\n\n                # Dynamic alpha: balance KD/CE over epochs\n                dynamic_alpha = alpha * (1 - epoch / epochs)\n                loss = (dynamic_alpha * temperature ** 2 * kd_loss +\n                        (1 - dynamic_alpha) * ce_loss) / accumulation_steps\n\n            scaler.scale(loss).backward()\n\n            if (i + 1) % accumulation_steps == 0 or i + 1 == len(trainloader):\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n\n            running_loss += loss.item() * accumulation_steps\n            _, predicted = student_outputs.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n\nscheduler.step()\n        test_acc = test_model(student_model, testloader)\n        print(f\"📘 Epoch {epoch+1}/{epochs} | Loss: {running_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n\n        if test_acc > best_acc:\n            best_acc = test_acc\n            early_stop_counter = 0\n            torch.save(student_model.state_dict(), \"best_kd_student.pth\")\n        else:\n            early_stop_counter += 0\n            if early_stop_counter >= patience:\n                print(\"⏹️ Early stopping triggered.\")\n                break\n\n    print(f\"✅ KD fine-tuning complete. Best Test Accuracy: {best_acc:.2f}%\")\n    return best_acc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install thop","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Importing Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nfrom thop import profile\nimport copy\nfrom collections import OrderedDict\nimport torch.nn.functional as F\nfrom torch.cuda.amp import autocast\nfrom torch.autograd import grad\nfrom collections import defaultdict\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Compute Model Accuracy","metadata":{}},{"cell_type":"code","source":"def compute_accuracy(model, test_loader, device=\"cuda\"):\n    model.to(device).eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    return 100 * correct / total\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Count Non-Zero Parameters in the Model","metadata":{}},{"cell_type":"code","source":"def count_non_zero_parameters(model):\n    return sum((param.ne(0)).sum().item() for param in model.parameters() if param.requires_grad)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Count Non-Zero Convolutional Filters","metadata":{}},{"cell_type":"code","source":"def count_nonzero_filters(model):\n    \"\"\"Count the total number of remaining convolutional filters (non-zero ones) in the model.\"\"\"\n    total_filters = 0\n    for layer in model.modules():\n        if isinstance(layer, nn.Conv2d):\n            # Count only filters (out_channels) that contain at least one non-zero weight\n            nonzero_filters = (layer.weight.abs().sum(dim=(1, 2, 3)) > 0).sum().item()\n            total_filters += nonzero_filters\n    return total_filters\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Compute Non-Zero FLOPs (Floating Point Operations)","metadata":{}},{"cell_type":"code","source":"def compute_nonzero_flops(model, input_size=(1, 3, 32, 32), device=\"cuda\"):\n    model.to(device)\n    inputs = torch.randn(input_size).to(device)\n    total_flops, _ = profile(model, inputs=(inputs,), verbose=False)\n    total_nonzero_flops = 0\n    for layer in model.modules():\n        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n            total_weights = layer.weight.numel()\n            nonzero_weights = (layer.weight.abs() > 0).sum().item()\n            sparsity_ratio = nonzero_weights / total_weights if total_weights > 0 else 0\n            total_nonzero_flops += total_flops * sparsity_ratio\n    return total_nonzero_flops / 1e6\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Test the Model's Performance","metadata":{}},{"cell_type":"code","source":"def test_model(model, testloader, device=\"cuda\"):\n    model.eval()\n    correct, total = 0, 0\n    criterion = nn.CrossEntropyLoss()\n    loss_total = 0\n    with torch.no_grad():\n        for images, labels in testloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss_total += criterion(outputs, labels).item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n    return (correct / total) * 100\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom functools import partial\nimport numpy as np\n\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom functools import partial\nfrom torch import nn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Pruning Function Definition","metadata":{}},{"cell_type":"code","source":"def differential_sensitivity_fusion_pruning(model, dataloader, device=\"cuda\"):\n    \"\"\"\n    Prunes filters based on differential sensitivity fusion of three importance metrics\n    \"\"\"\n    model.to(device).eval()\n    importance = {}\n    activations, gradients = {}, {}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Defining Forward and Backward Hooks","metadata":{}},{"cell_type":"code","source":"    def forward_hook(name, module, input, output):\n        activations[name] = output.detach()\n\n    def backward_hook(name, module, grad_input, grad_output):\n        gradients[name] = grad_output[0].detach()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Registering Hooks for Each Convolutional Layer","metadata":{}},{"cell_type":"code","source":"    hooks = []\n    for name, module in model.named_modules():\n        if isinstance(module, nn.Conv2d):\n            hooks.append(module.register_forward_hook(partial(forward_hook, name)))\n            hooks.append(module.register_backward_hook(partial(backward_hook, name)))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Forward and Backward Pass for Sensitivity Calculation","metadata":{}},{"cell_type":"code","source":"    # Forward and backward pass\n    images, labels = next(iter(dataloader))\n    images, labels = images.to(device), labels.to(device)\n    outputs = model(images)\n    loss = F.cross_entropy(outputs, labels)\n    loss.backward()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Removing Hooks After Computation","metadata":{}},{"cell_type":"code","source":"    # Remove hooks\n    for hook in hooks:\n        hook.remove()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Calculating Importance Metrics for Each Convolutional Layer","metadata":{}},{"cell_type":"code","source":"    # Calculate importance for each convolutional layer\n    for name in activations.keys():\n        if name not in gradients:\n            continue\n            \n        activation, grad = activations[name], gradients[name]\n        \n        # Compute components\n        grad_sensitivity = grad.abs().mean(dim=(0, 2, 3))\n        weight = dict(model.named_parameters())[f\"{name}.weight\"]\n        taylor_expansion = (grad.mean(dim=(2, 3)) * weight.norm(p=2, dim=(1, 2, 3))).abs().mean(dim=0)\n        \n        batch_mean_activation = activation.mean(dim=(2, 3), keepdim=True)\n        activation_prob = F.softmax(activation, dim=1)\n        batch_mean_prob = F.softmax(batch_mean_activation, dim=1) + 1e-10\n        kl_divergence = F.kl_div(batch_mean_prob.log(), activation_prob, reduction=\"none\").sum(dim=(0, 2, 3))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Fusion of sensitivity Metrics","metadata":{}},{"cell_type":"code","source":"        # Differential sensitivity fusion\n        diff1 = torch.exp(torch.abs(grad_sensitivity - taylor_expansion))\n        diff2 = torch.exp(torch.abs(taylor_expansion - kl_divergence))\n        diff3 = torch.exp(torch.abs(grad_sensitivity - kl_divergence))  \n        \n        sensitivity_fusion = diff1 + diff2 + 0.5 * diff3 \n\n        importance[name] = sensitivity_fusion.detach().cpu().numpy()\nreturn importance","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Bandit Agent for pruning","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models\nimport numpy as np\nimport random\nimport gc\n\nclass BanditAgent:\n    def __init__(self, num_layers, lr=0.01, gamma=0.99, buffer_size=512, mixing_net_hidden=32, epsilon_decay=0.995):\n        self.num_layers = num_layers\n        self.lr = lr\n        self.gamma = gamma\n        self.buffer_size = buffer_size\n        self.epsilon = 1.0\n        self.epsilon_decay = epsilon_decay\n\n        self.agent_nets = nn.ModuleList([\n            nn.Sequential(\n                nn.Linear(2, mixing_net_hidden),\n                nn.ReLU(),\n                nn.Linear(mixing_net_hidden, 1)\n            ) for _ in range(num_layers)\n        ]).to(\"cuda\")\n\nself.optimizer = optim.Adam(self.agent_nets.parameters(), lr=lr)\n        self.q_table = {layer: random.uniform(10, 90) for layer in range(num_layers)}\n        self.replay_buffer = []\n\n    def select_action(self, layer_idx, base_pruning_rate):\n        base_pruning_rate = min(100, max(0, base_pruning_rate))\n        if random.random() < self.epsilon:\n            min_rate = max(10, base_pruning_rate - 5)\n            max_rate = min(90, base_pruning_rate + 5)\n            return random.uniform(min_rate, max_rate)\nreturn self.q_table[layer_idx]\n\n    def store_experience(self, state, action, reward):\n        if len(self.replay_buffer) >= self.buffer_size:\n            self.replay_buffer.pop(0)\n        self.replay_buffer.append((state, action, reward))\n\n    def update_q_values(self):\n        if len(self.replay_buffer) < 32:\n            return\n\n        batch = random.sample(self.replay_buffer, min(len(self.replay_buffer), 64))\n        states, actions, rewards = zip(*batch)\nstates = torch.tensor(states, dtype=torch.float32).to(\"cuda\")\n        actions = torch.tensor(actions, dtype=torch.float32).view(-1, 1).to(\"cuda\")\n        rewards = torch.tensor(rewards, dtype=torch.float32).view(-1, 1).to(\"cuda\")\n\n        loss = 0\n        for i in range(self.num_layers):\n            q_vals = self.agent_nets[i](states)\n            loss += F.mse_loss(q_vals, q_vals.detach() + rewards)\n\n        self.optimizer.zero_grad()\n        loss.backward()\n        self.optimizer.step()\n\n        self.epsilon = max(self.epsilon * self.epsilon_decay, 0.01)\n\n        for layer_idx in range(self.num_layers):\n            state_tensor = torch.tensor([[0.5, layer_idx / self.num_layers]], dtype=torch.float32).to(\"cuda\")\n            predicted_value = self.agent_nets[layer_idx](state_tensor).item() * 100\n            self.q_table[layer_idx] = max(10, min(90, predicted_value))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Improved bandit-based pruning function for percentage rates","metadata":{}},{"cell_type":"code","source":"def prune_with_bandit(model, bandit_agent, pruning_rate, importance_method, dataloader, device=\"cuda\"):\n    pruning_rate = min(100, max(0, pruning_rate))\n    print(f\"Base pruning rate: {pruning_rate:.1f}%\")\n\n    conv_layers = []\n    conv_layer_names = []\n    for name, module in model.named_modules():\n        if isinstance(module, nn.Conv2d):\n            conv_layers.append(module)\n            conv_layer_names.append(name)\n\n    num_conv_layers = len(conv_layers)\n    print(f\"Number of convolutional layers: {num_conv_layers}\")\n\n    model.train()\n    for param in model.parameters():\n        param.requires_grad_(True)\n\n\nif importance_method == \"Sensitivity\":\n        importance = differential_sensitivity_fusion_pruning(model, dataloader, device=device)\n    else:\n        raise ValueError(f\"Unknown importance method: {importance_method}\")\n\n    with torch.no_grad():\n        total_filters = sum(layer.weight.shape[0] for layer in conv_layers)\n        pruned_filters = 0\n\n        for layer_idx, (layer, name) in enumerate(zip(conv_layers, conv_layer_names)):\n            importance_layer = importance.get(name, None)\n            if importance_layer is None:\n                print(f\"Skipping layer {name}: No importance scores found.\")\n                continue\n\nimportance_layer = torch.tensor(importance_layer, dtype=torch.float32, device=device)\n            assert importance_layer.shape[0] == layer.weight.shape[0]\n\n            layer_pruning_rate_pct = bandit_agent.select_action(layer_idx, pruning_rate)\n            layer_pruning_rate_pct = max(10, min(95, layer_pruning_rate_pct))\n            layer_pruning_rate = layer_pruning_rate_pct / 100.0\n\n            print(f\"Layer {name}: Pruning {layer_pruning_rate_pct:.1f}% of filters\")\n\n            num_filters = layer.weight.shape[0]\n            num_filters_to_keep = int(num_filters * (1 - layer_pruning_rate))\n\n            sorted_importance, sorted_indices = torch.sort(importance_layer, descending=True)\n            threshold = sorted_importance[num_filters_to_keep - 1] if num_filters_to_keep > 0 else float('inf')\n            mask = (importance_layer >= threshold).float().to(device)\n\n            non_zero_before = layer.weight.data.nonzero().size(0)\n            layer.weight.data.mul_(mask.view(-1, 1, 1, 1))\n            if layer.bias is not None:\n                layer.bias.data.mul_(mask.view(-1))\n            non_zero_after = layer.weight.data.nonzero().size(0)\n\n            filters_pruned = mask.numel() - mask.sum().item()\n            pruned_filters += filters_pruned\n\npruning_efficiency = 1.0 - (non_zero_after / non_zero_before)\n            reward = pruning_efficiency * (1.0 - abs(layer_pruning_rate_pct - pruning_rate) / 100)\n            state = [pruning_rate / 100, layer_idx / num_conv_layers]\n            bandit_agent.store_experience(state, layer_pruning_rate_pct, reward)\n\n        print(f\"Total filters pruned: {pruned_filters}/{total_filters} ({pruned_filters / total_filters * 100:.2f}%)\")\n        bandit_agent.update_q_values()\n        print(\"Pruning process complete.\")\n\n    return model\n\nbase_model = model\nbase_acc=0 \n\n# Initialize \"Agent\"\nbandit_agent = BanditAgent(num_layers=5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Main execution with the updated pruning methods","metadata":{}},{"cell_type":"code","source":"def generate_pruning_table(model, trainloader, testloader, pruning_rates, device=\"cuda\"):\n    base_model,base_acc= fine_tune_base_model(model, trainloader, testloader, epochs=40, lr=0.001, weight_decay=1e-4, accumulation_steps=4, device=\"cuda\")\n    print(f\"Base model accuracy: {base_acc}\")\n    base_params = count_non_zero_parameters(base_model)\n    base_flops = compute_nonzero_flops(base_model)\n    base_filters = count_nonzero_filters(base_model)\n\n    results = [[\"Base\", round(base_acc, 4), \"-\", base_filters, round(base_params / 1e6, 4), round(base_flops / 1e6, 4)]]\n\n    for rate in pruning_rates:\n        print(f\"Pruning at {rate}%...\")\n        \n        importance_methods = [\"Sensitivity\"]\n\n        for method in importance_methods:\n            print(f\"Applying {method} pruning...\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load a fresh model copy","metadata":{}},{"cell_type":"code","source":"pruned_model = load_model(device)\n            pruned_model.to(device)\n\n            pruned_model = prune_with_bandit(pruned_model, bandit_agent, rate, method, trainloader, device=\"cuda\")\n\n            acc_pruned = compute_accuracy(pruned_model, testloader, device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use knowledge distillation for fine-tuning","metadata":{}},{"cell_type":"code","source":"acc_finetuned = fine_tune_with_kd(\n                student_model=pruned_model,\n                teacher_model=base_model,  # Use the fine-tuned base model as teacher\n                trainloader=trainloader,\n                testloader=testloader,\n                epochs = 700,\n                device=device\n            )\n            \n            #acc_finetuned = fine_tune_model(pruned_model, trainloader, testloader, epochs=100, lr=0.001, weight_decay=1e-4, accumulation_steps=4, device=\"cuda\")\n            params_pruned = count_non_zero_parameters(pruned_model)\n            flops_pruned = compute_nonzero_flops(pruned_model)\n            filters_pruned = count_nonzero_filters(pruned_model)\n\n            print(\"Accuracy: \", acc_pruned)\n            print(\"Accuracy after finetuning with KD: \", acc_finetuned)\n            print(\"Filters pruned: \", base_filters - filters_pruned)\n            print(\"Flops pruned: \", base_flops - flops_pruned)\n\n            results.append([\n                f\"{method} ({rate}%)\",\n                round(acc_pruned, 4),\n                f\"{round(acc_finetuned, 4)} ({round(100 * acc_finetuned / base_acc, 2)}%)\",\n                filters_pruned,\n                round(params_pruned / 1e6, 4),\n                round(flops_pruned / 1e6, 4)\n            ])\n\n# Memory Cleanup\n            del pruned_model\n            gc.collect()\n            torch.cuda.empty_cache()\n            torch.cuda.synchronize()\n\n    df = pd.DataFrame(results, columns=[\"Method\", \"Acc. (pruned)\", \"Acc. (fine-tuned)\", \"Filters\", \"Params(M)\", \"FLOPs(M)\"])\n    return df\n\npruning_rates = [50,60,70]\n\n\ntable = generate_pruning_table(model, train_loader, test_loader, pruning_rates, device=\"cuda\")\nprint(table)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Print Function","metadata":{}},{"cell_type":"code","source":"base_model,base_acc= fine_tune_base_model(model, train_loader, test_loader, epochs=400, lr=0.001, weight_decay=1e-4, accumulation_steps=4, device=\"cuda\")\nprint(f\"Base model accuracy: {base_acc}\")\nbase_params = count_non_zero_parameters(base_model)\nbase_flops = compute_nonzero_flops(base_model)\nbase_filters = count_nonzero_filters(base_model)\n\nresults = [[\"Base\", round(base_acc, 4), \"-\", base_filters, round(base_params / 1e6, 4), round(base_flops / 1e6, 4)]]\nprint(results)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}